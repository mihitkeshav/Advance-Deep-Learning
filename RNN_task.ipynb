{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "RNN-task.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mihitkeshav/Advance-Deep-Learning/blob/master/RNN_task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuhvI0o8OIDu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "7b6ccae5-386a-44c8-84ed-bd6d241bbe1f"
      },
      "source": [
        "! shred -u setup_google_colab.py\n",
        "! wget https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py -O setup_google_colab.py\n",
        "import setup_google_colab\n",
        "# please, uncomment the week you're working on\n",
        "# setup_google_colab.setup_week1()\n",
        "# setup_google_colab.setup_week2()\n",
        "# setup_google_colab.setup_week2_honor()\n",
        "# setup_google_colab.setup_week3()\n",
        "# setup_google_colab.setup_week4()\n",
        "setup_google_colab.setup_week5()\n",
        "# setup_google_colab.setup_week6()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-08 10:06:17--  https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3636 (3.6K) [text/plain]\n",
            "Saving to: ‘setup_google_colab.py’\n",
            "\n",
            "\rsetup_google_colab.   0%[                    ]       0  --.-KB/s               \rsetup_google_colab. 100%[===================>]   3.55K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-05-08 10:06:17 (38.5 MB/s) - ‘setup_google_colab.py’ saved [3636/3636]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HVDnDgaOGCo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a3e5a589-0ce5-4169-87da-6802dc25f283"
      },
      "source": [
        "# set tf 1.x for colab\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGPwR2SdOGCw",
        "colab_type": "text"
      },
      "source": [
        "# Generating names with recurrent neural networks\n",
        "\n",
        "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
        "\n",
        "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
        "\n",
        "It's dangerous to go alone, take these:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.696201Z",
          "start_time": "2018-08-13T20:26:38.104103Z"
        },
        "id": "yYiIxkF7OGCx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "f007d54f-676b-4bd3-9e3d-aed23531d7a4"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "import keras_utils\n",
        "import tqdm_utils"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Byc_yXv8OGC8",
        "colab_type": "text"
      },
      "source": [
        "# Load data\n",
        "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
        "\n",
        "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.701832Z",
          "start_time": "2018-08-13T20:26:42.697766Z"
        },
        "id": "QzkdS9N7OGC9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start_token = \" \"  # so that the network knows that we're generating a first token\n",
        "\n",
        "# this is the token for padding,\n",
        "# we will add fake pad token at the end of names \n",
        "# to make them of equal size for further batching\n",
        "pad_token = \"#\"\n",
        "\n",
        "with open(\"names\") as f:\n",
        "    names = f.read()[:-1].split('\\n')\n",
        "    names = [start_token + name for name in names]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.707885Z",
          "start_time": "2018-08-13T20:26:42.703302Z"
        },
        "id": "Y29wS_DgOGDC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "a3e6f0f4-464e-4654-bd45-9f8bff1722ae"
      },
      "source": [
        "print('number of samples:', len(names))\n",
        "for x in names[::1000]:\n",
        "    print(x)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of samples: 7944\n",
            " Abagael\n",
            " Claresta\n",
            " Glory\n",
            " Liliane\n",
            " Prissie\n",
            " Geeta\n",
            " Giovanne\n",
            " Piggy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.857411Z",
          "start_time": "2018-08-13T20:26:42.709371Z"
        },
        "id": "Mr2G5vbbOGDN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "f1bd87e1-ca8e-4743-e095-40fd6cc1b91b"
      },
      "source": [
        "MAX_LENGTH = max(map(len, names))\n",
        "print(\"max length:\", MAX_LENGTH)\n",
        "\n",
        "plt.title('Sequence length distribution')\n",
        "plt.hist(list(map(len, names)), bins=25);"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max length: 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKBcN5yHOGDY",
        "colab_type": "text"
      },
      "source": [
        "# Text processing\n",
        "\n",
        "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.864592Z",
          "start_time": "2018-08-13T20:26:42.858725Z"
        },
        "id": "V5LfxBQPOGDa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dafb0731-c33c-4dae-a94f-53b21891e55d"
      },
      "source": [
        "tokens = set(''.join(names))### YOUR CODE HERE: all unique characters go here, padding included!\n",
        "tokens.add(pad_token)\n",
        "tokens = list(tokens)\n",
        "n_tokens = len(tokens)\n",
        "print ('n_tokens:', n_tokens)\n",
        "\n",
        "assert 50 < n_tokens < 60"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n_tokens: 56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5_9S-0COGDh",
        "colab_type": "text"
      },
      "source": [
        "### Cast everything from symbols into identifiers\n",
        "\n",
        "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
        "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
        "\n",
        "To create such dictionary, let's assign `token_to_id`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.870330Z",
          "start_time": "2018-08-13T20:26:42.866135Z"
        },
        "id": "ObQpofD0OGDi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "26a6cefc-49ca-4b4c-87a5-a7392a643d21"
      },
      "source": [
        "token_to_id =  {val : idx  for idx, val in enumerate(tokens)}  ## YOUR CODE HERE: create a dictionary of {symbol -> its  index in tokens}\n",
        "\n",
        "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\"\n",
        "print(token_to_id)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'c': 0, 'B': 1, 'N': 2, ' ': 3, 's': 4, 't': 5, 'x': 6, '-': 7, 'p': 8, 'M': 9, 'C': 10, 'm': 11, 'T': 12, 'X': 13, 'a': 14, 'd': 15, 'K': 16, 'i': 17, 'G': 18, 'U': 19, 'n': 20, 'S': 21, 'E': 22, 'j': 23, 'e': 24, \"'\": 25, 'R': 26, 'Y': 27, 'L': 28, 'b': 29, 'P': 30, 'V': 31, 'o': 32, 'y': 33, 'v': 34, 'O': 35, 'A': 36, 'k': 37, 'r': 38, 'z': 39, 'g': 40, 'l': 41, 'I': 42, 'f': 43, 'F': 44, 'w': 45, 'Q': 46, 'D': 47, 'q': 48, 'J': 49, '#': 50, 'u': 51, 'H': 52, 'W': 53, 'h': 54, 'Z': 55}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.875943Z",
          "start_time": "2018-08-13T20:26:42.871834Z"
        },
        "id": "UCLOA_qkOGDs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_matrix(names, max_len=None, pad=token_to_id[pad_token], dtype=np.int32):\n",
        "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
        "    \n",
        "    max_len = max_len or max(map(len, names))\n",
        "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
        "\n",
        "    for i in range(len(names)):\n",
        "        name_ix = list(map(token_to_id.get, names[i]))\n",
        "        names_ix[i, :len(name_ix)] = name_ix\n",
        "\n",
        "    return names_ix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.883107Z",
          "start_time": "2018-08-13T20:26:42.877186Z"
        },
        "id": "cPsVKyu2OGDx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "bc053541-6fa7-4e60-b2a5-79ecee7af99c"
      },
      "source": [
        "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
        "print('\\n'.join(names[::2000]))\n",
        "print(to_matrix(names[::2000]))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Abagael\n",
            " Glory\n",
            " Prissie\n",
            " Giovanne\n",
            "[[ 3 36 29 14 40 14 24 41 50]\n",
            " [ 3 18 41 32 38 33 50 50 50]\n",
            " [ 3 30 38 17  4  4 17 24 50]\n",
            " [ 3 18 17 32 34 14 20 20 24]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLUgInLTOGD7",
        "colab_type": "text"
      },
      "source": [
        "# Defining a recurrent neural network\n",
        "\n",
        "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/rnn.png?raw=1\" width=600>\n",
        "\n",
        "Since we're training a language model, there should also be:\n",
        "* An embedding layer that converts character id x_t to a vector.\n",
        "* An output layer that predicts probabilities of next phoneme based on h_t+1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.039419Z",
          "start_time": "2018-08-13T20:26:42.884581Z"
        },
        "id": "4m5QX7QNOGD9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remember to reset your session if you change your graph!\n",
        "s = keras_utils.reset_tf_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.044903Z",
          "start_time": "2018-08-13T20:26:44.041084Z"
        },
        "id": "WtcTiRGuOGEB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.layers import concatenate, Dense, Embedding\n",
        "\n",
        "rnn_num_units = 64  # size of hidden state\n",
        "embedding_size = 16  # for characters\n",
        "\n",
        "# Let's create layers for our recurrent network\n",
        "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
        "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
        "\n",
        "# an embedding layer that converts character ids into embeddings\n",
        "embed_x = Embedding(n_tokens, embedding_size)\n",
        "\n",
        "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
        "get_h_next = Dense(rnn_num_units, activation='tanh')### YOUR CODE HERE\n",
        "\n",
        "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
        "get_probas = Dense(n_tokens, activation='softmax') ### YOUR CODE HERE "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D25kTQagOGEL",
        "colab_type": "text"
      },
      "source": [
        "We will generate names character by character starting with `start_token`:\n",
        "\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/char-nn.png?raw=1\" width=600>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.053212Z",
          "start_time": "2018-08-13T20:26:44.048389Z"
        },
        "id": "hNYHvfZ3OGEN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rnn_one_step(x_t, h_t):\n",
        "    \"\"\"\n",
        "    Recurrent neural network step that produces \n",
        "    probabilities for next token x_t+1 and next state h_t+1\n",
        "    given current input x_t and previous state h_t.\n",
        "    We'll call this method repeatedly to produce the whole sequence.\n",
        "    \n",
        "    You're supposed to \"apply\" above layers to produce new tensors.\n",
        "    Follow inline instructions to complete the function.\n",
        "    \"\"\"\n",
        "    # convert character id into embedding\n",
        "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
        "    \n",
        "    # concatenate x_t embedding and previous h_t state\n",
        "    x_and_h =  concatenate([x_t_emb, h_t])### YOUR CODE HERE\n",
        "    \n",
        "    # compute next state given x_and_h\n",
        "    h_next = get_h_next(x_and_h) ### YOUR CODE HERE\n",
        "    \n",
        "    # get probabilities for language model P(x_next|h_next)\n",
        "    output_probas = get_probas(h_next) ### YOUR CODE HERE\n",
        "    \n",
        "    return output_probas, h_next"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rU_7yCaSOGET",
        "colab_type": "text"
      },
      "source": [
        "# RNN: loop\n",
        "\n",
        "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
        "\n",
        "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.342948Z",
          "start_time": "2018-08-13T20:26:44.056136Z"
        },
        "id": "Gl0cAhN5OGEU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
        "batch_size = tf.shape(input_sequence)[0]\n",
        "\n",
        "predicted_probas = []\n",
        "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
        "\n",
        "for t in range(MAX_LENGTH):\n",
        "    x_t = input_sequence[:, t]  # column t\n",
        "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
        "    \n",
        "    h_prev = h_next\n",
        "    predicted_probas.append(probas_next)\n",
        "    \n",
        "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
        "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
        "\n",
        "# next to last token prediction is not needed\n",
        "predicted_probas = predicted_probas[:, :-1, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69qlsExgOGEe",
        "colab_type": "text"
      },
      "source": [
        "# RNN: loss and gradients\n",
        "\n",
        "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
        "\n",
        "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
        "\n",
        "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.354310Z",
          "start_time": "2018-08-13T20:26:44.344648Z"
        },
        "id": "B65GRNvLOGEf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# flatten predictions to [batch*time, n_tokens]\n",
        "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
        "\n",
        "# flatten answers (next tokens) and one-hot encode them\n",
        "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvRWfA8iOGEk",
        "colab_type": "text"
      },
      "source": [
        "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
        "\n",
        "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
        "\n",
        "For simplicity you can ignore this comment, it's up to you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:45.076642Z",
          "start_time": "2018-08-13T20:26:44.355594Z"
        },
        "id": "iJqvQwFiOGEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
        "# Mind that predictions are probabilities and NOT logits!\n",
        "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
        "loss = -tf.reduce_mean(answers_matrix*tf.log(predictions_matrix))### YOUR CODE HERE\n",
        "\n",
        "optimize = tf.train.AdamOptimizer().minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJLb4MSIOGEs",
        "colab_type": "text"
      },
      "source": [
        "# RNN: training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.322187Z",
          "start_time": "2018-08-13T20:26:45.078296Z"
        },
        "id": "nrYVS9iwOGEt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "7e0f40a9-5238-46fd-fb3c-ad5dafbfc5e9"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "batch_size = 32\n",
        "history = []\n",
        "\n",
        "for i in range(1000):\n",
        "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
        "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
        "    \n",
        "    history.append(loss_i)\n",
        "    \n",
        "    if (i + 1) % 100 == 0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history, label='loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEBNFQTROGEx",
        "colab_type": "text"
      },
      "source": [
        "# RNN: sampling\n",
        "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.341196Z",
          "start_time": "2018-08-13T20:26:55.323787Z"
        },
        "id": "0QmSApJiOGEy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_t = tf.placeholder(tf.int32, (1,))\n",
        "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
        "\n",
        "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
        "# We reuse all parameters thanks to functional API usage.\n",
        "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
        "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
        "next_probs, next_h = rnn_one_step(x_t, h_t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.346422Z",
          "start_time": "2018-08-13T20:26:55.342659Z"
        },
        "id": "QxA7CJnyOGE2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
        "    '''\n",
        "    This function generates text given a `seed_phrase` as a seed.\n",
        "    Remember to include start_token in seed phrase!\n",
        "    Parameter `max_length` is used to set the number of characters in prediction.\n",
        "    '''\n",
        "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
        "    s.run(tf.assign(h_t, h_t.initial_value))\n",
        "    \n",
        "    # feed the seed phrase, if any\n",
        "    for ix in x_sequence[:-1]:\n",
        "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
        "    \n",
        "    # start generating\n",
        "    for _ in range(max_length-len(seed_phrase)):\n",
        "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
        "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
        "        \n",
        "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:58.458115Z",
          "start_time": "2018-08-13T20:26:55.347900Z"
        },
        "id": "YzmbU2iROGE-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "eed4447a-5949-4190-da41-399edfedff72"
      },
      "source": [
        "# without prefix\n",
        "for _ in range(10):\n",
        "    print(generate_sample())"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " varalie\n",
            " Janaen\n",
            " Mardy\n",
            " Sarbei\n",
            " Donta\n",
            " Bimce\n",
            " Is\n",
            " Shethned\n",
            " Baalrac\n",
            " Fcalfe\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:01.986726Z",
          "start_time": "2018-08-13T20:26:58.459810Z"
        },
        "id": "fmmxJ3y-OGFG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "d195febb-ed1b-48dd-d3eb-33b3bebc2810"
      },
      "source": [
        "# with prefix conditioning\n",
        "for _ in range(10):\n",
        "    print(generate_sample(' Trump'))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Trump\n",
            " Trumplabe\n",
            " Trumpa\n",
            " Trumpertn\n",
            " Trumpeegmit\n",
            " Trumphe\n",
            " Trumplag\n",
            " Trumpa\n",
            " Trumpa\n",
            " Trumpan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1OnM-I_OGFO",
        "colab_type": "text"
      },
      "source": [
        "# Submit to Coursera"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:02.004926Z",
          "start_time": "2018-08-13T20:40:02.000821Z"
        },
        "id": "fKg3Y_TmOGFQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# token expires every 30 min\n",
        "COURSERA_TOKEN = \"Kl6VzlDRuOHJl8Fr\"\n",
        "COURSERA_EMAIL = \"mihitraj@ymail.com\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:18.923357Z",
          "start_time": "2018-08-13T20:40:03.549343Z"
        },
        "id": "vaKLURZ6OGFV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "5186d0ad-d5b3-474b-bbfd-afe51dc648d5"
      },
      "source": [
        "from submit import submit_char_rnn\n",
        "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
        "submission = (history, samples)\n",
        "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************\n",
            "\n",
            "Submitted to Coursera platform. See results on assignment page!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skVdLX0YOGFb",
        "colab_type": "text"
      },
      "source": [
        "# Try it out!\n",
        "\n",
        "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
        "\n",
        "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
        "\n",
        "* Novels/poems/songs of your favorite author\n",
        "* News titles/clickbait titles\n",
        "* Source code of Linux or Tensorflow\n",
        "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
        "* Melody in notes/chords format\n",
        "* IKEA catalog titles\n",
        "* Pokemon names\n",
        "* Cards from Magic, the Gathering / Hearthstone\n",
        "\n",
        "If you're willing to give it a try, here's what you wanna look at:\n",
        "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
        "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
        "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
        "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
        "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
        "\n",
        "__Good hunting!__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "MiVfSc67OGFc",
        "colab_type": "text"
      },
      "source": [
        "# Bonus level: dynamic RNNs\n",
        "\n",
        "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
        "\n",
        "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
        "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
        "\n",
        "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.975354Z",
          "start_time": "2018-08-13T20:27:12.737529Z"
        },
        "id": "x-dutK9BOGFf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "outputId": "e0b509bf-17d6-4500-8799-e6f90822dea5"
      },
      "source": [
        "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
        "    def call(self, input, state):\n",
        "        # from docs:\n",
        "        # Returns:\n",
        "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
        "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
        "        return rnn_one_step(input[:, 0], state)\n",
        "    \n",
        "    @property\n",
        "    def output_size(self):\n",
        "        return n_tokens\n",
        "    \n",
        "cell = CustomRNN(rnn_num_units)\n",
        "\n",
        "input_sequence = tf.placeholder(tf.float32, (None, None))\n",
        "    \n",
        "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
        "\n",
        "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
        "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-34-932903461488>:13: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-34-932903461488>:17: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn_cell_impl.py:456: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn_cell_impl.py:460: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:Entity <bound method CustomRNN.call of <__main__.CustomRNN object at 0x7f92f0a5d4a8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method CustomRNN.call of <__main__.CustomRNN object at 0x7f92f0a5d4a8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "LSTM outputs for each step [batch,time,n_tokens]:\n",
            "(10, 50, 56)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LrH2koJOGFk",
        "colab_type": "text"
      },
      "source": [
        "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
        "\n",
        "You can also use any pre-implemented RNN cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.981697Z",
          "start_time": "2018-08-13T20:27:12.977590Z"
        },
        "id": "6feGgFP7OGFl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "d52cc2dd-2321-433b-da29-ee4a1b3fdc6a"
      },
      "source": [
        "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
        "    if obj.endswith('Cell'):\n",
        "        print(obj, end=\"\\t\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "BasicLSTMCell\tBasicRNNCell\tGRUCell\tLSTMCell\tMultiRNNCell\tRNNCell\tBasicLSTMCell\tBasicRNNCell\tBidirectionalGridLSTMCell\tConv1DLSTMCell\tConv2DLSTMCell\tConv3DLSTMCell\tConvLSTMCell\tCoupledInputForgetGateLSTMCell\tFusedRNNCell\tGLSTMCell\tGRUBlockCell\tGRUCell\tGridLSTMCell\tIndRNNCell\tIndyGRUCell\tIndyLSTMCell\tIntersectionRNNCell\tLSTMBlockCell\tLSTMBlockFusedCell\tLSTMCell\tLayerNormBasicLSTMCell\tLayerRNNCell\tMultiRNNCell\tNASCell\tPhasedLSTMCell\tRNNCell\tSRUCell\tTimeFreqLSTMCell\tUGRNNCell\t"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:13.168207Z",
          "start_time": "2018-08-13T20:27:12.986884Z"
        },
        "id": "NCE-q846OGFp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "outputId": "8fa281cf-6971-46e2-e1bf-83d3433c0c4c"
      },
      "source": [
        "input_sequence = tf.placeholder(tf.float32, (None, None))\n",
        "\n",
        "inputs_embedded = embed_x(input_sequence)\n",
        "\n",
        "# standard cell returns hidden state as output!\n",
        "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
        "\n",
        "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
        "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-36-ae4a02207412>:6: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mBuildLoop\u001b[0;34m(self, pred, body, loop_vars, shape_invariants, return_same_structure)\u001b[0m\n\u001b[1;32m   2244\u001b[0m         original_body_result, exit_vars = self._BuildLoop(\n\u001b[0;32m-> 2245\u001b[0;31m             pred, body, original_loop_vars, loop_vars, shape_invariants)\n\u001b[0m\u001b[1;32m   2246\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m_BuildLoop\u001b[0;34m(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\u001b[0m\n\u001b[1;32m   2169\u001b[0m     \u001b[0mpre_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2170\u001b[0;31m     \u001b[0mbody_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpacked_vars_for_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2171\u001b[0m     \u001b[0mpost_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i, lv)\u001b[0m\n\u001b[1;32m   2704\u001b[0m             math_ops.logical_and(i < maximum_iterations, orig_cond(*lv)))\n\u001b[0;32m-> 2705\u001b[0;31m         \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2706\u001b[0m       \u001b[0mtry_to_pack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn.py\u001b[0m in \u001b[0;36m_time_step\u001b[0;34m(time, output_ta_t, state)\u001b[0m\n\u001b[1;32m    883\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m       \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m     \u001b[0mcall_cell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, state, scope, *args, **kwargs)\u001b[0m\n\u001b[1;32m    385\u001b[0m     return base_layer.Layer.__call__(\n\u001b[0;32m--> 386\u001b[0;31m         self, inputs, state, scope=scope, *args, **kwargs)\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    547\u001b[0m       \u001b[0;31m# Actually call layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    801\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbuild_graph\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_keras_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 802\u001b[0;31m       \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_keras_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36mcreate_keras_history\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    183\u001b[0m   \"\"\"\n\u001b[0;32m--> 184\u001b[0;31m   \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreated_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_keras_history_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mcreated_layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36m_create_keras_history_helper\u001b[0;34m(tensors, processed_ops, created_layers)\u001b[0m\n\u001b[1;32m    230\u001b[0m       processed_ops, created_layers = _create_keras_history_helper(\n\u001b[0;32m--> 231\u001b[0;31m           layer_inputs, processed_ops, created_layers)\n\u001b[0m\u001b[1;32m    232\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36m_create_keras_history_helper\u001b[0;34m(tensors, processed_ops, created_layers)\u001b[0m\n\u001b[1;32m    230\u001b[0m       processed_ops, created_layers = _create_keras_history_helper(\n\u001b[0;32m--> 231\u001b[0;31m           layer_inputs, processed_ops, created_layers)\n\u001b[0m\u001b[1;32m    232\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36m_create_keras_history_helper\u001b[0;34m(tensors, processed_ops, created_layers)\u001b[0m\n\u001b[1;32m    230\u001b[0m       processed_ops, created_layers = _create_keras_history_helper(\n\u001b[0;32m--> 231\u001b[0;31m           layer_inputs, processed_ops, created_layers)\n\u001b[0m\u001b[1;32m    232\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36m_create_keras_history_helper\u001b[0;34m(tensors, processed_ops, created_layers)\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m               \u001b[0mconstants\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m       processed_ops, created_layers = _create_keras_history_helper(\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3441\u001b[0;31m     \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3442\u001b[0m     \u001b[0mfeed_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m(op_input_list)\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m       \u001b[0m_initialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m_initialize_variables\u001b[0;34m(session)\u001b[0m\n\u001b[1;32m    902\u001b[0m     is_initialized = session.run(\n\u001b[0;32m--> 903\u001b[0;31m         [variables_module.is_variable_initialized(v) for v in candidate_vars])\n\u001b[0m\u001b[1;32m    904\u001b[0m     \u001b[0muninitialized_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1386\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1387\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1388\u001b[0m       \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/util/lock_util.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_group_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/util/lock_util.py\u001b[0m in \u001b[0;36macquire\u001b[0;34m(self, group_id)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_another_group_active\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_group_member_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgroup_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-ae4a02207412>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn_cell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTMCell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_num_units\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mstate_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn.py\u001b[0m in \u001b[0;36mdynamic_rnn\u001b[0;34m(cell, inputs, sequence_length, initial_state, dtype, parallel_iterations, swap_memory, time_major, scope)\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0msequence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m         dtype=dtype)\n\u001b[0m\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m     \u001b[0;31m# Outputs of _dynamic_rnn_loop are always shaped [time, batch, depth].\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn.py\u001b[0m in \u001b[0;36m_dynamic_rnn_loop\u001b[0;34m(cell, inputs, initial_state, parallel_iterations, swap_memory, sequence_length, dtype)\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0mparallel_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m       swap_memory=swap_memory)\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m   \u001b[0;31m# Unpack final output if not using output tuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2751\u001b[0m       \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWHILE_CONTEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2752\u001b[0m     result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants,\n\u001b[0;32m-> 2753\u001b[0;31m                                     return_same_structure)\n\u001b[0m\u001b[1;32m   2754\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmaximum_iterations\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2755\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mBuildLoop\u001b[0;34m(self, pred, body, loop_vars, shape_invariants, return_same_structure)\u001b[0m\n\u001b[1;32m   2243\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2244\u001b[0m         original_body_result, exit_vars = self._BuildLoop(\n\u001b[0;32m-> 2245\u001b[0;31m             pred, body, original_loop_vars, loop_vars, shape_invariants)\n\u001b[0m\u001b[1;32m   2246\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2247\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/util/lock_util.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_arg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_arg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback_arg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mtype_arg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_arg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback_arg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_group_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/util/lock_util.py\u001b[0m in \u001b[0;36mrelease\u001b[0;34m(self, group_id)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_group_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_group_member_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgroup_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_group_member_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgroup_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmlbc3aHuLa4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}